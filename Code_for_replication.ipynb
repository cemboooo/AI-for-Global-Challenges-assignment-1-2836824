{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7KTZtS8sUfS"
      },
      "outputs": [],
      "source": [
        "#Upload the files\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM\n",
        "import numpy as np\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from matplotlib import pyplot\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "\n",
        "rmse2 = 0\n",
        "\n",
        "tr_filename=\"train_NREL_solar_data.csv\"\n",
        "train_data = np.loadtxt(tr_filename,delimiter=',')\n",
        "\n",
        "va_filename=\"validate_NREL_solar_data.csv\"\n",
        "validate_data = np.loadtxt(va_filename,delimiter=',')\n",
        "\n",
        "te_filename=\"test_NREL_solar_data.csv\"\n",
        "test_data = np.loadtxt(te_filename,delimiter=',')\n",
        "\n",
        "x_tr  = train_data[:,0:9]\n",
        "t_tr  = train_data[:,-1]\n",
        "\n",
        "x_va  = validate_data[:,0:9]\n",
        "t_va  = validate_data[:,-1]\n",
        "\n",
        "x_te  = test_data[:,0:9]\n",
        "t_te  = test_data[:,-1]\n",
        "\n",
        "Ndays_tr = x_tr.shape[0]//11\n",
        "Ndays_va = x_va.shape[0]//11\n",
        "Ndays_te = x_te.shape[0]//11\n",
        "\n",
        "train_x = x_tr.reshape(Ndays_tr,11,9)\n",
        "train_t = t_tr.reshape(Ndays_tr,11,1)\n",
        "\n",
        "validate_x = x_va.reshape(Ndays_va,11,9)\n",
        "validate_t = t_va.reshape(Ndays_va,11,1)\n",
        "\n",
        "test_x = x_te.reshape(Ndays_te,11,9)\n",
        "test_t = t_te.reshape(Ndays_te,11,1)\n",
        "\n",
        "model = Sequential()\n",
        "    #model.add(LSTM(30,input_shape=(11,9)))\n",
        "    #model.add(Dense(9,activation='linear'))\n",
        "    #model.add(LSTM(input_dim=9,output_dim=25,return_sequences=True))\n",
        "model.add(LSTM(50,input_shape=(11,9),return_sequences=True))\n",
        "model.add(Dense(1,activation='linear'))\n",
        "model.compile(loss='mse',optimizer='adam')\n",
        "    #history = model.fit(train_x,train_t,epochs=50,validation_data=(test_x,test_t))\n",
        "history = model.fit(train_x,train_t,epochs=100,batch_size=50,validation_data=(validate_x,validate_t))\n",
        "\n",
        "pyplot.plot(history.history['loss'],label='train')\n",
        "    #pyplot.plot(history.history['val_loss'],label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()\n",
        "\n",
        "yhat = model.predict(test_x)\n",
        "y_te = yhat.reshape(Ndays_te*11,)\n",
        "\n",
        "rmse2 += mean_squared_error(y_te,t_te)*Ndays_te*11\n",
        "\n",
        "rmse = sqrt(rmse2/4026)*1087.4396/2\n",
        "print('Test RMSE: %.3F' % rmse)"
      ],
      "metadata": {
        "id": "Ae4LpgI1sVav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear Regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#Reshape data to hourly format\n",
        "x_tr_hourly = x_tr.reshape(-1, 9)  # All hours, 9 features each\n",
        "t_tr_hourly = t_tr.reshape(-1)     # Target values for each hour\n",
        "\n",
        "x_te_hourly = x_te.reshape(-1, 9)\n",
        "t_te_hourly = t_te.reshape(-1)\n",
        "\n",
        "#Train Linear Regression on hourly data\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(x_tr_hourly, t_tr_hourly)\n",
        "\n",
        "#Predict and denormalize\n",
        "lr_preds_hourly = lr_model.predict(x_te_hourly)\n",
        "lr_preds_denorm = (lr_preds_hourly + 1) * 700\n",
        "test_t_denorm = (t_te_hourly + 1) * 700\n",
        "\n",
        "#Compute RMSE\n",
        "rmse_lr = sqrt(mean_squared_error(test_t_denorm, lr_preds_denorm))\n",
        "print(f'Linear Regression Test RMSE: {rmse_lr} W/m²')"
      ],
      "metadata": {
        "id": "kwH4XGgcsX-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Persistence\n",
        "# Reshape into days\n",
        "x_te_days = x_te.reshape(Ndays_te, 11, 9)\n",
        "t_te_days = t_te.reshape(Ndays_te, 11)\n",
        "\n",
        "# Create arrays to store predictions and actual values\n",
        "all_predictions = []\n",
        "all_actuals = []\n",
        "\n",
        "# For each day except the first one\n",
        "for day_idx in range(1, Ndays_te):\n",
        "    # Use the previous day's values as predictions for the current day\n",
        "    previous_day_values = t_te_days[day_idx-1, :]\n",
        "    current_day_actuals = t_te_days[day_idx, :]\n",
        "\n",
        "    all_predictions.append(previous_day_values)\n",
        "    all_actuals.append(current_day_actuals)\n",
        "\n",
        "# Convert to arrays\n",
        "persistence_preds = np.array(all_predictions)\n",
        "target_vals = np.array(all_actuals)\n",
        "\n",
        "# Denormalize\n",
        "max_irradiance = 700\n",
        "persistence_preds_denorm = (persistence_preds + 1) * (max_irradiance/2)\n",
        "target_vals_denorm = (target_vals + 1) * (max_irradiance/2)\n",
        "\n",
        "# Compute RMSE\n",
        "rmse_persistence = np.sqrt(np.mean((target_vals_denorm.flatten() - persistence_preds_denorm.flatten())**2))\n",
        "print(f'Persistence Model RMSE: {rmse_persistence:.4f} W/m²')"
      ],
      "metadata": {
        "id": "qhq1NIQgslxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BPNN\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "#Constants from the paper\n",
        "GHI_MIN = 0\n",
        "GHI_MAX = 1400  #Based on paper’s expected GHI range\n",
        "normaliasation_scale = GHI_MAX / 2  #for RMSE rescaling like LSTM code\n",
        "\n",
        "#Extract inputs and targets\n",
        "x_tr = train_data[:, 0:9]\n",
        "t_tr = train_data[:, -1]\n",
        "x_va = validate_data[:, 0:9]\n",
        "t_va = validate_data[:, -1]\n",
        "x_te = test_data[:, 0:9]\n",
        "t_te = test_data[:, -1]\n",
        "\n",
        "#Normalize inputs to [-1, 1]\n",
        "min_vals = x_tr.min(axis=0)\n",
        "max_vals = x_tr.max(axis=0)\n",
        "\n",
        "def normalize(x):\n",
        "    return 2 * (x - min_vals) / (max_vals - min_vals) - 1\n",
        "\n",
        "x_tr = normalize(x_tr)\n",
        "x_va = normalize(x_va)\n",
        "x_te = normalize(x_te)\n",
        "\n",
        "#Reshape data into sequences of 11 hours\n",
        "Ndays_tr = x_tr.shape[0] // 11\n",
        "Ndays_va = x_va.shape[0] // 11\n",
        "Ndays_te = x_te.shape[0] // 11\n",
        "\n",
        "train_x = x_tr.reshape(Ndays_tr, 99)\n",
        "validate_x = x_va.reshape(Ndays_va, 99)\n",
        "test_x = x_te.reshape(Ndays_te, 99)\n",
        "\n",
        "train_t = t_tr.reshape(Ndays_tr, 11)\n",
        "validate_t = t_va.reshape(Ndays_va, 11)\n",
        "test_t = t_te.reshape(Ndays_te, 11)\n",
        "\n",
        "#BPNN Model\n",
        "model = Sequential([\n",
        "    Dense(50, activation='tanh', input_shape=(99,)),\n",
        "    Dense(11, activation='linear')\n",
        "])\n",
        "\n",
        "optimizer = SGD(learning_rate=0.01, momentum=0.0)\n",
        "model.compile(optimizer=optimizer, loss='mse')\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=50,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "#Train\n",
        "history = model.fit(\n",
        "    train_x, train_t,\n",
        "    validation_data=(validate_x, validate_t),\n",
        "    epochs=2500,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "#Denormalize predicted and true values\n",
        "def denormalize(data):\n",
        "    return (data + 1) * normaliasation_scale  # same as * 1400 / 2\n",
        "\n",
        "predictions = model.predict(test_x)\n",
        "predictions_denorm = denormalize(predictions)\n",
        "test_t_denorm = denormalize(test_t)\n",
        "\n",
        "#Calculate RMSE\n",
        "rmse = sqrt(mean_squared_error(test_t_denorm.flatten(), predictions_denorm.flatten()))\n",
        "print(f'\\nBPNN Test RMSE: {rmse} W/m²')\n",
        "print(f'Best epoch: {np.argmin(history.history[\"val_loss\"]) + 1}')\n",
        "\n",
        "#Plot Training History\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE Loss')\n",
        "plt.title('BPNN Training History')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wVHaG6iNstO4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}